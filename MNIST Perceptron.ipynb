{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Luke Cathcart\n",
    "#915-648-747\n",
    "#CS 545\n",
    "#Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import random as random\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull in data\n",
    "train = pd.read_excel(\"C:/Users/Veteran/Documents/Luke's School/Terms/Fall 2019/CS 545/mnist_train.xlsx\", header = None)\n",
    "extra = train\n",
    "#Pull in test dataset\n",
    "test = pd.read_excel(\"C:/Users/Veteran/Documents/Luke's School/Terms/Fall 2019/CS 545/mnist_test.xlsx\", header = None)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#Shuffle Training Set\n",
    "train = skl.utils.shuffle(train)\n",
    "train = np.asmatrix(train)\n",
    "\n",
    "t = train[:,0] #Actual number digits.\n",
    "print(train.shape)\n",
    "train = np.delete(train, 0, 1)\n",
    "print(train.shape)\n",
    "x = np.asarray(train)\n",
    "n_train = len(train)\n",
    "\n",
    "test = extrat\n",
    "#Preprocessing\n",
    "#Shuffle Test Set\n",
    "test = skl.utils.shuffle(test)\n",
    "test = np.asmatrix(test)\n",
    "\n",
    "t_test = test[:,0] #Actual number digits.\n",
    "print(test.shape)\n",
    "test = np.delete(test, 0, 1)\n",
    "print(test.shape)\n",
    "x_test = np.asarray(test)\n",
    "n_test = len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "#For each learning rate, this cell and the one below will need to be run.\n",
    "#This cell with re-randomize the weights and change the learning rate.\n",
    "#Learning Rate\n",
    "eta = 0.001 #Change this for each learning rate.\n",
    "#Create weights(w)\n",
    "w = np.random.uniform(-0.05,0.05,(10,785))#Weight vector\n",
    "\n",
    "#Perceptrons\n",
    "#We need to train ten perceptrons simultaneously on all data.\n",
    "#Epoch 0 is present in this code. \n",
    "#Loop 1 (epoch) will train the 10 perceptrons on all of the data 51 times counting epoch 0.\n",
    "#Loop 2 (i) will send the perceptron through all of the training data.\n",
    "#Loop 3 (p) will train all of the perceptrons.\n",
    "#Loop 4 (j) will recalculate the weights.\n",
    "#Loop 5 (k) will calculate the accuracy.\n",
    "#Run through the training set.\n",
    "train_acc_rate_vec = []\n",
    "test_acc_rate_vec = []\n",
    "for epoch in range(0,51):\n",
    "    pred = [] #We already have the actual values in \"t\" above.\n",
    "    for i in range(0,n_train):\n",
    "        t[i] = int(t[i])\n",
    "        att = np.asarray([0,0,0,0,0,0,0,0,0,0])\n",
    "        att[t[i]] = 1\n",
    "        xi = x[i].astype('float16')/255 #Scale data into [0,1]\n",
    "        x0 = 1\n",
    "        xi = np.hstack((x0,xi))\n",
    "        xi = xi.reshape(1,785)\n",
    "        y = [] #Vector in {0,1} based on whether the neuron fires or not.\n",
    "        z = [] #Vector of inner products of w & x for each perceptron.\n",
    "        for p in range(10):\n",
    "            zi = np.inner(xi,w[p,:]) #Output of sum(w*x)\n",
    "            if (zi > 0):\n",
    "                yi = 1\n",
    "            else:\n",
    "                yi = 0    \n",
    "            z.append(zi)    \n",
    "            y.append(yi)\n",
    "        z = np.asarray(z)\n",
    "        pred.append(np.argmax(z))\n",
    "\n",
    "        for j in range(10):\n",
    "            w[j,:] = w[j,:] + (eta*(att[j] - y[j])*xi)\n",
    "            #print(w)\n",
    "        \n",
    "    acc_train = 0\n",
    "    for k in range(0, n_train):\n",
    "        if (t[k] == pred[k]):\n",
    "            acc_train += 1\n",
    "        else:\n",
    "            acc_train = acc_train\n",
    "    acc_rate = (acc_train/n_train)\n",
    "    train_acc_rate_vec.append(acc_rate)\n",
    "    print(\"Train accuracy at\", epoch, \"out of 50 is\", acc_rate)\n",
    "\n",
    "#Run through the test set.\n",
    "    pred_test = [] #We already have the actual values in \"t\" above.\n",
    "    for i in range(0,n_test):\n",
    "        t_test[i] = int(t_test[i])\n",
    "        att = np.asarray([0,0,0,0,0,0,0,0,0,0])\n",
    "        att[t_test[i]] = 1\n",
    "        xi_test = x_test[i].astype('float16')/255 #Scale data into [0,1]\n",
    "        x0 = 1\n",
    "        xi_test = np.hstack((x0,xi_test))\n",
    "        xi_test = xi_test.reshape(1,785)\n",
    "        y = [] #Vector in {0,1} based on whether the neuron fires or not.\n",
    "        z = [] #Vector of inner products of w & x for each perceptron.\n",
    "        for p in range(10):\n",
    "            zi = np.inner(xi_test,w[p,:]) #Output of sum(w*x)\n",
    "            if (zi > 0):\n",
    "                yi = 1\n",
    "            else:\n",
    "                yi = 0    \n",
    "            z.append(zi)    \n",
    "            y.append(yi)\n",
    "        z = np.asarray(z)\n",
    "        pred_test.append(np.argmax(z))\n",
    "\n",
    "        \n",
    "    acc_test = 0\n",
    "    for k in range(0,n_test):\n",
    "        if (t_test[k] == pred_test[k]):\n",
    "            acc_test += 1\n",
    "        else:\n",
    "            acc_test = acc_test\n",
    "    acc_rate_test = (acc_test/n_test)\n",
    "    test_acc_rate_vec.append(acc_rate_test)\n",
    "    print(\"Test accuracy at\", epoch, \"out of 50 is\", acc_rate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need the confusion matrix\n",
    "confusion = confusion_matrix(t_test, pred_test)\n",
    "print(\"Confusion Matrix for eta =\", eta, \"is\", confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
